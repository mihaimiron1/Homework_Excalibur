{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you have the latest version of sigmoid_check installed by running pip install sigmoid_check --upgrade\n",
    "from sigmoid_check.excalibur import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Extract DataFrame `df_social_media_metrics` subset for rows where 'Likes' exceed 'Shares' and store it in `highly_liked_posts`.\n",
    "@check_pandas_101\n",
    "def pandas_101(df_social_media_metrics):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    highly_liked_posts = df_social_media_metrics[df_social_media_metrics[\"Likes\"] > df_social_media_metrics[\"Shares\"]]\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"highly_liked_posts\": highly_liked_posts}\n",
    "\n",
    "pandas_101()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use DataFrame `df_product_info` to group by 'Category', computing the minimum 'Price' for each category, storing result as `min_price_by_category`.\n",
    "@check_pandas_102\n",
    "def pandas_102(df_product_info):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    min_price_by_category = df_product_info.groupby(\"Category\")[\"Price\"].min()\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"min_price_by_category\": min_price_by_category}\n",
    "\n",
    "pandas_102()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Apply datetime filtering on `df_online_sessions` to store sessions in the month of January 2023 in variable `january_sessions` based on 'SessionStart'.\n",
    "@check_pandas_103\n",
    "def pandas_103(df_online_sessions):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    df_online_sessions[\"SessionStart\"] = pd.to_datetime(df_online_sessions[\"SessionStart\"])\n",
    "    january_sessions = df_online_sessions[(df_online_sessions[\"SessionStart\"].dt.year == 2023) & (df_online_sessions[\"SessionStart\"].dt.month == 1)]\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"january_sessions\": january_sessions}\n",
    "\n",
    "pandas_103()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use DataFrame `df_employee_entries` and fill NA in 'EntryTime' with '08:00 AM', storing the result in `filled_employee_entries`.\n",
    "@check_pandas_104\n",
    "def pandas_104(df_employee_entries):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    filled_employee_entries = df_employee_entries.fillna({\"EntryTime\": \"08:00 AM\"})\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"filled_employee_entries\": filled_employee_entries}\n",
    "\n",
    "pandas_104()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Drop all columns with any NA values in DataFrame `df_transaction_records`, storing cleaned version as `non_na_transactions`.\n",
    "@check_pandas_105\n",
    "def pandas_105(df_transaction_records):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    non_na_transactions = df_transaction_records.dropna(axis=1)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"non_na_transactions\": non_na_transactions}\n",
    "\n",
    "pandas_105()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a Series `series_ascending` from a list of numbers [1, 2, 3, 4, 5], using these values as the indices as well.\n",
    "@check_pandas_106\n",
    "def pandas_106():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    series_ascending = pd.Series([1, 2, 3, 4, 5], index=[1, 2, 3, 4, 5])\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"series_ascending\": series_ascending}\n",
    "\n",
    "pandas_106()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use the query method on DataFrame `df_financial_audit` to extract entries with 'Audit' == 'Complete' and 'Amount' > 10000, saving it as `completed_audits`.\n",
    "@check_pandas_107\n",
    "def pandas_107(df_financial_audit):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    completed_audits = df_financial_audit.query(\"Audit == 'Complete' and Amount > 10000\")\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"completed_audits\": completed_audits}\n",
    "\n",
    "pandas_107()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Create a custom `percent_round` function and apply it to round the 'Progress' column in DataFrame `df_student_projects` to the nearest ten, storing result as `rounded_progress`.\n",
    "@check_pandas_108\n",
    "def pandas_108(df_student_projects):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def percent_round(x):\n",
    "        return round(x, -1)\n",
    "    rounded_progress = df_student_projects[\"Progress\"].apply(percent_round)\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"rounded_progress\": rounded_progress}\n",
    "\n",
    "pandas_108()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Extract the elements starting from the 10th index to the 20th index from `df_user_activity`, storing the result in `sampled_user_activity`.\n",
    "@check_pandas_109\n",
    "def pandas_109(df_user_activity):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    sampled_user_activity = df_user_activity.iloc[10:21]\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"sampled_user_activity\": sampled_user_activity}\n",
    "\n",
    "pandas_109()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use advanced indexing to set all negative values in DataFrame `df_temperature_fluctuations` to zero, storing corrected DataFrame as `non_negative_temperatures`.\n",
    "@check_pandas_110\n",
    "def pandas_110(df_temperature_fluctuations):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    non_negative_temperatures = df_temperature_fluctuations.copy()\n",
    "    non_negative_temperatures[non_negative_temperatures < 0] = 0\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"non_negative_temperatures\": non_negative_temperatures}\n",
    "\n",
    "pandas_110()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# With DataFrame `df_fleet_inventory`, allocate memory efficiency by converting 'Year' column to category, saving the result as `efficient_fleet_inventory`.\n",
    "@check_pandas_111\n",
    "def pandas_111(df_fleet_inventory):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    efficient_fleet_inventory = df_fleet_inventory.copy()\n",
    "    efficient_fleet_inventory[\"Year\"] = efficient_fleet_inventory[\"Year\"].astype(\"category\")\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"efficient_fleet_inventory\": efficient_fleet_inventory}\n",
    "\n",
    "pandas_111()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use DataFrame `df_respiratory_data` to calculate cumulative maximum of 'Pulse' within groups of 'PatientID', storing it as `grouped_cumulative_max`.\n",
    "@check_pandas_112\n",
    "def pandas_112(df_respiratory_data):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    grouped_cumulative_max = df_respiratory_data.groupby(\"PatientID\")[\"Pulse\"].cummax()\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"grouped_cumulative_max\": grouped_cumulative_max}\n",
    "\n",
    "pandas_112()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Group DataFrame `df_weather_statistics` and apply aggregation to find both 'mean' and 'std' of 'Temperature', storing multi-aggregate result as `weather_stats`.\n",
    "@check_pandas_113\n",
    "def pandas_113(df_weather_statistics):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    weather_stats = df_weather_statistics.groupby(\"City\")[\"Temperature\"].agg([\"mean\", \"std\"])\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"weather_stats\": weather_stats}\n",
    "\n",
    "pandas_113()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a hierarchical index on DataFrame `df_multilayer_data` using [('Region', 'State')], saving the result as `hierarchical_multilayer`.\n",
    "@check_pandas_114\n",
    "def pandas_114(df_multilayer_data):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    hierarchical_multilayer = df_multilayer_data.set_index(['Region', 'State'])\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"hierarchical_multilayer\": hierarchical_multilayer}\n",
    "\n",
    "pandas_114()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the exponential moving average with a span of 10 on the 'Close' column in DataFrame `df_market_activity`, storing to `ema_market_activity`.\n",
    "@check_pandas_115\n",
    "def pandas_115(df_market_activity):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    ema_market_activity = df_market_activity[\"Close\"].ewm(span=10).mean()\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"ema_market_activity\": ema_market_activity}\n",
    "\n",
    "pandas_115()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame `df_temperature_readings` for two sensors over the year using monthly datetime index, with lineaerly increasing temperature values from 20 to 30 for Sensor1 and 15 to 25 for Sensor2.\n",
    "@check_pandas_116\n",
    "def pandas_116():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    date_range = pd.date_range(start=\"2023-01-01\", end=\"2023-12-31\", freq=\"ME\")\n",
    "    df_temperature_readings = pd.DataFrame({\n",
    "        \"Sensor1\": np.linspace(20, 30, num=12),\n",
    "        \"Sensor2\": np.linspace(15, 25, num=12)\n",
    "    }, index\n",
    "    =date_range)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"df_temperature_readings\": df_temperature_readings}\n",
    "\n",
    "pandas_116()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use DataFrame `df_sales_tiers` to add a 'SalesTier' column assigned by binning the 'Sales' column into 'Low', 'Medium', and 'High' categories based on [0, 5000, 10000, 15000] bins, storing as `tiered_sales`.\n",
    "@check_pandas_117\n",
    "def pandas_117(df_sales_tiers):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    bins = [0, 5000, 10000, 15000]\n",
    "    labels = [\"Low\", \"Medium\", \"High\"]\n",
    "    tiered_sales = df_sales_tiers.copy()\n",
    "    tiered_sales[\"SalesTier\"] = pd.cut(tiered_sales[\"Sales\"], bins=bins, labels=labels)\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"tiered_sales\": tiered_sales}\n",
    "\n",
    "pandas_117()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Extract month at index of DataFrame `df_time_based_events`, storing them as a new column 'EventMonth' in the DataFrame.\n",
    "@check_pandas_118\n",
    "def pandas_118(df_time_based_events):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    df_time_based_events[\"EventMonth\"] = df_time_based_events[\"EventDate\"].dt.month\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"df_time_based_events\": df_time_based_events}\n",
    "\n",
    "pandas_118()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Given a DataFrame `df_tennis_matches`, select rows using .loc where 'MatchesPlayed' > 20 and store them as `consistent_players`.\n",
    "@check_pandas_119\n",
    "def pandas_119(df_tennis_matches):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    consistent_players = df_tennis_matches.loc[df_tennis_matches[\"MatchesPlayed\"] > 20]\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"consistent_players\": consistent_players}\n",
    "\n",
    "pandas_119()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Utilize .iloc on DataFrame `df_daily_results` to select rows by integer location, focusing on every third row, and storing result as `every_third_result`.\n",
    "@check_pandas_120\n",
    "def pandas_120(df_daily_results):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    every_third_result = df_daily_results.iloc[::3]\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"every_third_result\": every_third_result}\n",
    "\n",
    "pandas_120()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# From DataFrame `df_survey_responses`, combine 'Question' and 'Answer' columns into a single 'Response' column, storing the result as a Series `consolidated_responses` in the format 'Question: Answer'.\n",
    "@check_pandas_121\n",
    "def pandas_121(df_survey_responses):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    consolidated_responses = df_survey_responses[\"Question\"] + \": \" + df_survey_responses[\"Answer\"]\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"consolidated_responses\": consolidated_responses}\n",
    "\n",
    "pandas_121()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use DataFrame `df_server_logs` to group by 'ServerID' and calculate the sum and max of 'ResponseTime', storing result as `server_response_summary`.\n",
    "@check_pandas_122\n",
    "def pandas_122(df_server_logs):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    server_response_summary = df_server_logs.groupby(\"ServerID\")[\"ResponseTime\"].agg([\"sum\", \"max\"])\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"server_response_summary\": server_response_summary}\n",
    "\n",
    "pandas_122()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Modify DataFrame `df_machine_operating` by adding column 'Downtime' calculated from 'EndTime' minus 'StartTime', storing as `operations_with_downtime`.\n",
    "@check_pandas_123\n",
    "def pandas_123(df_machine_operating):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    df_machine_operating[\"StartTime\"] = pd.to_datetime(df_machine_operating[\"StartTime\"])\n",
    "    df_machine_operating[\"EndTime\"] = pd.to_datetime(df_machine_operating[\"EndTime\"])\n",
    "    df_machine_operating[\"Downtime\"] = df_machine_operating[\"EndTime\"] - df_machine_operating[\"StartTime\"]\n",
    "    operations_with_downtime = df_machine_operating\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"operations_with_downtime\": operations_with_downtime}\n",
    "\n",
    "pandas_123()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows from DataFrame `df_patient_visits`, considering only 'PatientID' and 'VisitDate', saving unique rows as `unique_patient_visits`.\n",
    "@check_pandas_124\n",
    "def pandas_124(df_patient_visits):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    unique_patient_visits = df_patient_visits.drop_duplicates(subset=[\"PatientID\", \"VisitDate\"])\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"unique_patient_visits\": unique_patient_visits}\n",
    "\n",
    "pandas_124()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Optimize data processing speed in DataFrame `df_satellite_data` by converting all text-based columns to category type, storing efficient version as `satellite_optimized`.\n",
    "@check_pandas_125\n",
    "def pandas_125(df_satellite_data):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    satellite_optimized = df_satellite_data.copy()\n",
    "    for col in satellite_optimized.select_dtypes(include=[\"object\"]).columns:\n",
    "        satellite_optimized[col] = satellite_optimized[col].astype(\"category\")\n",
    "        \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"satellite_optimized\": satellite_optimized}\n",
    "\n",
    "pandas_125()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use vectorized operations on DataFrame `df_temperature_logs` to convert 'TemperatureC' to Fahrenheit, storing the result in `temperature_fahrenheit`.\n",
    "@check_pandas_126\n",
    "def pandas_126(df_temperature_logs):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    temperature_fahrenheit = df_temperature_logs[\"TemperatureC\"] * 9/5 + 32\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"temperature_fahrenheit\": temperature_fahrenheit}\n",
    "\n",
    "pandas_126()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Group DataFrame `df_streaming_data` by 'UserID' and apply a lambda function to compute total view time, storing the result as `total_view_time`.\n",
    "@check_pandas_127\n",
    "def pandas_127(df_streaming_data):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    total_view_time = df_streaming_data.groupby(\"UserID\")[\"ViewTime\"].agg(lambda x: x.sum())\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"total_view_time\": total_view_time}\n",
    "\n",
    "pandas_127()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Use DataFrame `df_sales_analytics` to implement cohort analysis, calculating first purchase date and cohort index, storing result in `sales_cohorts`.\n",
    "@check_pandas_128\n",
    "def pandas_128(df_sales_analytics):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"sales_cohorts\": sales_cohorts}\n",
    "\n",
    "pandas_128()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# In DataFrame `df_web_traffic`, apply conversion to 'Date' column from string to datetime, saving the updated DataFrame as `web_traffic_dates`.\n",
    "@check_pandas_129\n",
    "def pandas_129(df_web_traffic):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    web_traffic_dates = df_web_traffic.copy()\n",
    "    web_traffic_dates[\"Date\"] = pd.to_datetime(web_traffic_dates[\"Date\"])\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"web_traffic_dates\": web_traffic_dates}\n",
    "\n",
    "pandas_129()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame `df_energy_savings` with datetime index representing bi-weekly dates over one year, filled with repetitive 5% and 10% energy savings, stored in 'SavingsPercent'.\n",
    "@check_pandas_130\n",
    "def pandas_130():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    date_range = pd.date_range(start=\"2023-01-01\", periods=26, freq=\"2W\")\n",
    "    df_energy_savings = pd.DataFrame({\n",
    "        \"SavingsPercent\": [5, 10] * 13\n",
    "    }, index=date_range)\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\\\n",
    "    return {\"df_energy_savings\": df_energy_savings}\n",
    "\n",
    "pandas_130()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# With DataFrame `df_vehicle_data`, apply method chaining to filter 'Type' as 'SUV' and sort by 'RecallDate', saving sorted SUVs as `sorted_suvs`.\n",
    "@check_pandas_131\n",
    "def pandas_131(df_vehicle_data):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    sorted_suvs = df_vehicle_data[df_vehicle_data[\"Type\"] == \"SUV\"].sort_values(\"RecallDate\")\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"sorted_suvs\": sorted_suvs}\n",
    "\n",
    "pandas_131()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Extract 'year' from 'DateAdmitted' in DataFrame `df_patient_admissions` using datetime operations, storing extracted years in `admission_years`.\n",
    "@check_pandas_132\n",
    "def pandas_132(df_patient_admissions):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    admission_years = df_patient_admissions[\"DateAdmitted\"].dt.year\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"admission_years\": admission_years}\n",
    "\n",
    "pandas_132()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Process DataFrame `df_cost_analysis` by converting 'Amount' to USD using 'Currency' which contains the type like ['EUR', 'GBP'] conversion rates being EUR: 1.12 and GBP: 1.30, storing result as `cost_analysis_usd` with column 'Amount' in 'Currency' and 'AmountUSD' in USD.\n",
    "@check_pandas_133\n",
    "def pandas_133(df_cost_analysis):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    conversion_rates = {\n",
    "        \"EUR\": 1.12,\n",
    "        \"GBP\": 1.30\n",
    "    }\n",
    "    cost_analysis_usd = df_cost_analysis.copy()\n",
    "    cost_analysis_usd[\"AmountUSD\"] = cost_analysis_usd[\"Amount\"] * cost_analysis_usd[\"Currency\"].map(conversion_rates)\n",
    "        \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"cost_analysis_usd\": cost_analysis_usd}\n",
    "\n",
    "pandas_133()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# In DataFrame `df_logistics_data`, use rolling window of 30 days to calculate moving average inventory level, storing as `thirty_day_moving_inventory`.\n",
    "@check_pandas_134\n",
    "def pandas_134(df_logistics_data):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    thirty_day_moving_inventory = df_logistics_data[\"InventoryLevel\"].rolling(window=30).mean()\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"thirty_day_moving_inventory\": thirty_day_moving_inventory}\n",
    "\n",
    "pandas_134()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# From DataFrame `df_sports_results`, extract top three teams based on 'Scores', sorting first, saving top teams as `top_teams`.\n",
    "@check_pandas_135\n",
    "def pandas_135(df_sports_results):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    top_teams = df_sports_results.nlargest(3, \"Scores\")\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"top_teams\": top_teams}\n",
    "\n",
    "pandas_135()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use DataFrame `df_network_activity` statistics to calculate z-scores for 'Bandwidth', storing in column 'ZscoreBandwidth' as `network_with_zscore`.\n",
    "@check_pandas_136\n",
    "def pandas_136(df_network_activity):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    df_network_activity[\"ZscoreBandwidth\"] = (df_network_activity[\"Bandwidth\"] - df_network_activity[\"Bandwidth\"].mean()) / df_network_activity[\"Bandwidth\"].std()\n",
    "    network_with_zscore = df_network_activity\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"network_with_zscore\": network_with_zscore}\n",
    "\n",
    "pandas_136()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Perform inplace boolean update of `df_market_responses` setting all 'ResponseTime' > 300 to 300, saving updated DataFrame.\n",
    "@check_pandas_137\n",
    "def pandas_137(df_market_responses):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    df_market_responses.loc[df_market_responses[\"ResponseTime\"] > 300, \"ResponseTime\"] = 300\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"df_market_responses\": df_market_responses}\n",
    "\n",
    "pandas_137()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Analyze DataFrame `df_social_behaviors` applying transform with a custom function to 'EngagementRate' to normalize within each 'Group' by z-score, storing as 'NormalizedEngagementRate'.\n",
    "@check_pandas_138\n",
    "def pandas_138(df_social_behaviors):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def zscore(x):\n",
    "        return (x - x.mean()) / x.std()\n",
    "    df_social_behaviors[\"NormalizedEngagementRate\"] = df_social_behaviors.groupby(\"Group\")[\"EngagementRate\"].transform(zscore)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"df_social_behaviors\": df_social_behaviors}\n",
    "\n",
    "pandas_138()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Use DataFrame `df_product_launch` to derive 'ResponseRate' from 'Inquiries' divided by 'Sales', multiplied by 100, storing as `launch_responses`.\n",
    "@check_pandas_139\n",
    "def pandas_139(df_product_launch):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"launch_responses\": launch_responses}\n",
    "\n",
    "pandas_139()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `create_series_from_dict` that takes a dictionary `input_dict` as an argument, and returns a pandas Series with the dictionary keys as the Series index.\n",
    "@check_pandas_140\n",
    "def pandas_3():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def create_series_from_dict(input_dict):\n",
    "        return pd.Series(input_dict)\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"create_series_from_dict\": create_series_from_dict}\n",
    "\n",
    "pandas_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define a function `filter_series_positive` that takes a pandas Series `data_series` and returns a new Series containing only the elements where the value is positive.\n",
    "@check_pandas_141\n",
    "def pandas_4():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def filter_series_positive(data_series):\n",
    "        return data_series[data_series > 0]\n",
    "                           \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"filter_series_positive\": filter_series_positive}\n",
    "\n",
    "pandas_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Develop a function `rename_dataframe_columns` that accepts a DataFrame `df` and a dictionary `column_mapping`, and returns the DataFrame with renamed columns according to the mapping.\n",
    "@check_pandas_142\n",
    "def pandas_142():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def rename_dataframe_columns(df, column_mapping):\n",
    "        return df.rename(columns=column_mapping)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"rename_dataframe_columns\": rename_dataframe_columns}\n",
    "\n",
    "pandas_142()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `drop_nan_rows` that takes a DataFrame `input_df` and returns a new DataFrame with all rows containing any NaN values removed.\n",
    "@check_pandas_143\n",
    "def pandas_143():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def drop_nan_rows(input_df):\n",
    "        return input_df.dropna()\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"drop_nan_rows\": drop_nan_rows}\n",
    "\n",
    "pandas_143()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Construct a function `fill_missing_with_mean` which takes a DataFrame `df` and fills missing values in each numeric column with the mean of that column, returning the modified DataFrame.\n",
    "@check_pandas_144\n",
    "def pandas_144():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def fill_missing_with_mean(df):\n",
    "        return df.fillna(df.mean())\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"fill_missing_with_mean\": fill_missing_with_mean}\n",
    "\n",
    "pandas_144()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `calculate_group_means` that takes a DataFrame `df` and a column name `group_col`, grouping by `group_col`, then returning the mean of each group as a Series.\n",
    "@check_pandas_145\n",
    "def pandas_145():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def calculate_group_means(df, group_col):\n",
    "        return df.groupby(group_col).mean()\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"calculate_group_means\": calculate_group_means}\n",
    "\n",
    "pandas_145()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Design a function `subset_dataframe_label` that accepts a DataFrame `df`, a list `rows` of row labels, and returns a subset DataFrame containing only those rows.\n",
    "@check_pandas_146\n",
    "def pandas_146():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def subset_dataframe_label(df, rows):\n",
    "        return df.loc[rows]\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"subset_dataframe_label\": subset_dataframe_label}\n",
    "\n",
    "pandas_146()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define a function `merge_dataframes_on_key` that takes two DataFrames `df1`, `df2`, and a string `key`, merging them on the shared key column and returning the merged DataFrame.\n",
    "@check_pandas_147\n",
    "def pandas_147():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def merge_dataframes_on_key(df1, df2, key):\n",
    "        return pd.merge(df1, df2, on=key)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"merge_dataframes_on_key\": merge_dataframes_on_key}\n",
    "\n",
    "pandas_147()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `aggregate_sales_by_region` which accepts a DataFrame `sales_df` that includes columns 'Region' and 'Sales', and returns a DataFrame with the total sales per region.\n",
    "@check_pandas_148\n",
    "def pandas_148():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def aggregate_sales_by_region(sales_df):\n",
    "        return sales_df.groupby(\"Region\")[\"Sales\"].sum().reset_index()\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"aggregate_sales_by_region\": aggregate_sales_by_region}\n",
    "\n",
    "pandas_148()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `pivot_table_for_analysis` that takes a DataFrame `df` and strings `index`, `columns`, `values`, and returns a pivot table using those specifications.\n",
    "@check_pandas_149\n",
    "def pandas_149():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def pivot_table_for_analysis(df, index, columns, values):\n",
    "        return pd.pivot_table(df, index=index, columns=columns, values=values)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"pivot_table_for_analysis\": pivot_table_for_analysis}\n",
    "\n",
    "pandas_149()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `calculate_rolling_average` that accepts a DataFrame `df` and an integer `window` to compute the rolling average of a numeric column `column_name`, returning the updated series.\n",
    "@check_pandas_150\n",
    "def pandas_150():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def calculate_rolling_average(df, column_name, window):\n",
    "        return df[column_name].rolling(window=window).mean()\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"calculate_rolling_average\": calculate_rolling_average}\n",
    "\n",
    "pandas_150()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Construct a function `resample_time_series` which takes a time-indexed DataFrame `time_df` and a frequency string `freq`, resampling the DataFrame to the new frequency and summing, returning the result.\n",
    "@check_pandas_151\n",
    "def pandas_151():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def resample_time_series(time_df, freq):\n",
    "        return time_df.resample(freq).sum()\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"resample_time_series\": resample_time_series}\n",
    "\n",
    "pandas_151()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `expand_string_columns` that takes a DataFrame `df` and a list of columns `string_columns`, expanding each string column to lowercase, and returns the modified DataFrame.\n",
    "@check_pandas_152\n",
    "def pandas_152():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def expand_string_columns(df, string_columns):\n",
    "        for col in string_columns:\n",
    "            df[col] = df[col].str.lower()\n",
    "        return df\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"expand_string_columns\": expand_string_columns}\n",
    "\n",
    "pandas_152()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Design a function `convert_to_datetime_index` that accepts a DataFrame `df` and a column name `date_col`, converting it to a DateTimeIndex, and returning the updated DataFrame.\n",
    "@check_pandas_153\n",
    "def pandas_153():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def convert_to_datetime_index(df, date_col):\n",
    "        df[date_col] = pd.to_datetime(df[date_col])\n",
    "        return df.set_index(date_col)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"convert_to_datetime_index\": convert_to_datetime_index}\n",
    "\n",
    "pandas_153()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `identify_and_remove_outliers` that identifies outliers in a Series `data_series` using a specified `threshold` by removing the values outside of the `threshodl` multiplied by the standard deviation from the mean.\n",
    "@check_pandas_154\n",
    "def pandas_154():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def identify_and_remove_outliers(data_series, threshold):\n",
    "        mean = data_series.mean()\n",
    "        std = data_series.std()\n",
    "        lower_bound = mean - threshold * std\n",
    "        upper_bound = mean + threshold * std\n",
    "        return data_series[(data_series > lower_bound) & (data_series < upper_bound)]\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"identify_and_remove_outliers\": identify_and_remove_outliers}\n",
    "\n",
    "pandas_154()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `calculate_percentage_change` which computes the percentage change over time for a Series `time_series` and returns the updated Series with NaN for the first entry.\n",
    "@check_pandas_155\n",
    "def pandas_155():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def calculate_percentage_change(time_series):\n",
    "        return time_series.pct_change()\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"calculate_percentage_change\": calculate_percentage_change}\n",
    "\n",
    "pandas_155()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define a function `categorize_based_on_values` which takes a DataFrame `df`, a column `categorical_col`, and returns a DataFrame with additional column 'Category' based on ranges in `categorical_col` with labels ['Low', 'Medium', 'High'] and bins [0, 100, 200, 300].\n",
    "@check_pandas_156\n",
    "def pandas_156():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def categorize_based_on_values(df, categorical_col):\n",
    "        bins = [0, 100, 200, 300]\n",
    "        labels = ['Low', 'Medium', 'High']\n",
    "        df['Category'] = pd.cut(df[categorical_col], bins=bins, labels=labels)\n",
    "        return df\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"categorize_based_on_values\": categorize_based_on_values}\n",
    "\n",
    "pandas_156()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `shift_dataframe_rows` that takes a DataFrame `df` and an integer `periods`, shifting all rows by the specified number of periods and returning the DataFrame.\n",
    "@check_pandas_157\n",
    "def pandas_157():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def shift_dataframe_rows(df, periods):\n",
    "        return df.shift(periods)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"shift_dataframe_rows\": shift_dataframe_rows}\n",
    "\n",
    "pandas_157()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Develop a function `aggregate_and_flatten_grouped` that takes a grouped DataFrame `group_df` and returns a flattened DataFrame with 'sum' and 'count' aggregation for each group and reseted index.\n",
    "@check_pandas_158\n",
    "def pandas_158():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def aggregate_and_flatten_grouped(group_df):\n",
    "        return group_df.agg({\"Column1\": [\"sum\", \"count\"]}).reset_index()\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"aggregate_and_flatten_grouped\": aggregate_and_flatten_grouped}\n",
    "\n",
    "pandas_158()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Construct a function named `remove_duplicates_by_columns` that takes a DataFrame `df` and a list `subset_columns`, and removes duplicate rows based on these columns, returning the resulting DataFrame.\n",
    "@check_pandas_159\n",
    "def pandas_159():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def remove_duplicates_by_columns(df, subset_columns):\n",
    "        return df.drop_duplicates(subset=subset_columns)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"remove_duplicates_by_columns\": remove_duplicates_by_columns}\n",
    "\n",
    "pandas_159()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Design a function `calculate_memory_usage` that takes a DataFrame `df` and returns the total memory usage in MB, both with and without optimizations for all columns possible.\n",
    "@check_pandas_160\n",
    "def pandas_160():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def calculate_memory_usage(df):\n",
    "        memory_usage = df.memory_usage(deep=True).sum() / 1024 ** 2\n",
    "        optimized_memory_usage = df.memory_usage(deep=True, index=False).sum() / 1024 ** 2\n",
    "        return memory_usage, optimized_memory_usage\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"calculate_memory_usage\": calculate_memory_usage}\n",
    "\n",
    "pandas_160()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `map_values_with_dict` which accepts a DataFrame `df`, a column `target_col`, and a dictionary `value_map`, returning the updated DataFrame after mapping.\n",
    "@check_pandas_161\n",
    "def pandas_161():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def map_values_with_dict(df, target_col, value_map):\n",
    "        df[target_col] = df[target_col].map(value_map)\n",
    "        return df\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"map_values_with_dict\": map_values_with_dict}\n",
    "\n",
    "pandas_161()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `select_top_n_rows_based_on_column` that takes a DataFrame `df`, a column `target_col`, and an integer `n`, and returns the top `n` rows sorted by `target_col`.\n",
    "@check_pandas_162\n",
    "def pandas_162():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def select_top_n_rows_based_on_column(df, target_col, n):\n",
    "        return df.sort_values(target_col, ascending=False).head(n)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"select_top_n_rows_based_on_column\": select_top_n_rows_based_on_column}\n",
    "\n",
    "pandas_162()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `replace_substrings_in_column` that takes a DataFrame `df`, a column `text_col`, a string `old`, and a string `new`, replacing all occurrences of `old` with `new` in `text_col`.\n",
    "@check_pandas_163\n",
    "def pandas_163():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def replace_substrings_in_column(df, text_col, old, new):\n",
    "        df[text_col] = df[text_col].str.replace(old, new)\n",
    "        return df\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"replace_substrings_in_column\": replace_substrings_in_column}\n",
    "\n",
    "pandas_163()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define a function `apply_discretization_binner` which bins Series `data_series` into a specified number of discrete intervals `n_bins` and returns the binned Series.\n",
    "@check_pandas_164\n",
    "def pandas_164():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def apply_discretization_binner(data_series, n_bins):\n",
    "        return pd.cut(data_series, bins=n_bins)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"apply_discretization_binner\": apply_discretization_binner}\n",
    "\n",
    "pandas_164()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `generate_descriptive_statistics` that takes a DataFrame `df` and returns a DataFrame with descriptive statistics such as mean, median, and standard deviation for all numeric columns.\n",
    "@check_pandas_165\n",
    "def pandas_165():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def generate_descriptive_statistics(df):\n",
    "        return df.describe()\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"generate_descriptive_statistics\": generate_descriptive_statistics}\n",
    "\n",
    "pandas_165()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `convert_column_dtype` that accepts a DataFrame `df`, a column name `col`, and a data type `new_type`, and returns the DataFrame with `col` converted to `new_type`.\n",
    "@check_pandas_166\n",
    "def pandas_166():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def convert_column_dtype(df, col, new_type):\n",
    "        df[col] = df[col].astype(new_type)\n",
    "        return df\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"convert_column_dtype\": convert_column_dtype}\n",
    "\n",
    "pandas_166()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Develop a function `sort_dataframe_by_multiple_columns` taking DataFrame `df` and a list `columns_list` to sort the DataFrame by these columns, returning the sorted DataFrame.\n",
    "@check_pandas_167\n",
    "def pandas_167():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def sort_dataframe_by_multiple_columns(df, columns_list):\n",
    "        return df.sort_values(columns_list)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"sort_dataframe_by_multiple_columns\": sort_dataframe_by_multiple_columns}\n",
    "\n",
    "pandas_167()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `create_time_based_features` which accepts a DataFrame `time_df` with a 'Timestamp' column and returns the DataFrame with new columns for hour, day, and month.\n",
    "@check_pandas_168\n",
    "def pandas_168():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def create_time_based_features(time_df):\n",
    "        time_df[\"Hour\"] = time_df[\"Timestamp\"].dt.hour\n",
    "        time_df[\"Day\"] = time_df[\"Timestamp\"].dt.day\n",
    "        time_df[\"Month\"] = time_df[\"Timestamp\"].dt.month\n",
    "        return time_df\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"create_time_based_features\": create_time_based_features}\n",
    "\n",
    "pandas_168()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `analyze_sales_data` that takes a DataFrame `sales_df` with columns 'Date', 'Region', and 'Sales'. The function should: Convert 'Date' to a DateTime object; Filter out any rows where 'Sales' is negative; Group by 'Region' to calculate the total and average sales; Return a DataFrame with columns 'Region', 'TotalSales', 'AverageSales';\n",
    "@check_pandas_169\n",
    "def pandas_169():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def analyze_sales_data(sales_df):\n",
    "        sales_df[\"Date\"] = pd.to_datetime(sales_df[\"Date\"])\n",
    "        sales_df = sales_df[sales_df[\"Sales\"] >= 0]\n",
    "        sales_summary = sales_df.groupby(\"Region\")[\"Sales\"].agg([\"sum\", \"mean\"]).reset_index()\n",
    "        sales_summary.columns = [\"Region\", \"TotalSales\", \"AverageSales\"]\n",
    "        return sales_summary\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"analyze_sales_data\": analyze_sales_data}\n",
    "\n",
    "pandas_169()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `clean_and_merge_datasets` that takes two DataFrames `df_left` and `df_right`, and: Fills NA values in `df_left` with 0; Drops any duplicate rows in `df_right`; Merges the cleaned DataFrames on a common column 'Key', using an outer join; Returns the merged DataFrame sorted by 'Key';\n",
    "@check_pandas_170\n",
    "def pandas_170():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def clean_and_merge_datasets(df_left, df_right):\n",
    "        df_left.fillna(0, inplace=True)\n",
    "        df_right.drop_duplicates(inplace=True)\n",
    "        merged_df = pd.merge(df_left, df_right, on=\"Key\", how=\"outer\")\n",
    "        return merged_df.sort_values(\"Key\")\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"clean_and_merge_datasets\": clean_and_merge_datasets}\n",
    "\n",
    "pandas_170()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Develop a function `process_sensor_data_batch` that receives a DataFrame `sensor_df` containing 'SensorID', 'ReadingValue', 'Timestamp'. Convert 'Timestamp' to datetime format; Ensure all 'ReadingValue' entries are non-negative; Calculate the mean and standard deviation of 'ReadingValue' for each 'SensorID'; Return a DataFrame with 'SensorID', 'MeanReading', 'StdDevReading';\n",
    "@check_pandas_171\n",
    "def pandas_171():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"process_sensor_data_batch\": process_sensor_data_batch}\n",
    "\n",
    "pandas_171()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Construct a function `analyze_customer_behaviors` to handle a DataFrame `customer_df` with columns 'CustomerID', 'PurchaseAmount', 'VisitTimestamp'. Convert 'VisitTimestamp' to a DateTimeIndex; Filter to include only purchases greater than a specified `min_purchase`; Group by 'CustomerID' to determine the total and count of purchases; Return a DataFrame with 'CustomerID', 'TotalPurchases', 'NumberVisits', and attach the most recent visit date;\n",
    "@check_pandas_172\n",
    "def pandas_172():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def analyze_customer_behaviors(customer_df, min_purchase):\n",
    "        customer_df[\"VisitTimestamp\"] = pd.to_datetime(customer_df[\"VisitTimestamp\"])\n",
    "        customer_df = customer_df[customer_df[\"PurchaseAmount\"] > min_purchase]\n",
    "        customer_summary = customer_df.groupby(\"CustomerID\").agg(\n",
    "            TotalPurchases=(\"PurchaseAmount\", \"sum\"),\n",
    "            NumberVisits=(\"PurchaseAmount\", \"count\"),\n",
    "            MostRecentVisit=(\"VisitTimestamp\", \"max\")\n",
    "        ).reset_index()\n",
    "        return customer_summary\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"analyze_customer_behaviors\": analyze_customer_behaviors}\n",
    "\n",
    "pandas_172()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `transform_financial_data` that processes a DataFrame `financial_df` including columns 'AccountID', 'TransactionDate', 'Amount'. Parse 'TransactionDate' into datetime and set as index; Filter 'Amount' to exclude NaN and zero values; Extract month and year from 'TransactionDate' into new columns `Month`, `Year`; Group by 'AccountID' and 'Year' to summarize monthly 'Amount' into sum and mean, returning a structured DataFrame;\n",
    "@check_pandas_173\n",
    "def pandas_173():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"transform_financial_data\": transform_financial_data}\n",
    "\n",
    "pandas_173()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `aggregate_weather_data` for a DataFrame `weather_df` with fields 'StationID', 'Temp', 'Humidity', 'ObservationTime'. Convert 'ObservationTime' to a DateTimeIndex; Filter to retain records with positive 'Temp' and 'Humidity'; Resample to daily frequency, taking the mean for each day; Return a DataFrame grouped by 'StationID' with columns for daily average 'Temp' and 'Humidity';\n",
    "@check_pandas_174\n",
    "def pandas_174():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"aggregate_weather_data\": aggregate_weather_data}\n",
    "\n",
    "pandas_174()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Design a function `standardize_student_record` to clean a DataFrame `student_df` featuring 'Name', 'Score', 'SubmissionDate'. Standardize 'Name' to have a capitalized first letter; Address missing 'Score' values by assigning the median score; Standardize 'SubmissionDate' to a consistent format and compute 'DaysSinceSubmission'; Return a DataFrame with standardized names, computed days since submission, and filled scores;\n",
    "@check_pandas_175\n",
    "def pandas_175():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"standardize_student_record\": standardize_student_record}\n",
    "\n",
    "pandas_175()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `construct_inventory_report` that takes a DataFrame `inventory_df` with 'ItemID', 'Quantity', 'RestockDate'. Parse 'RestockDate' to ensure it's in datetime format; Identify items needing restock by checking 'Quantity' against the `threshold`; Provide a summary count of items needing restock by month; Return a detailed DataFrame with 'ItemID', 'Quantity', 'DaysUntilRestock', plus a monthly summary DataFrame;\n",
    "@check_pandas_176\n",
    "def pandas_176():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def construct_inventory_report(inventory_df, threshold):\n",
    "        inventory_df[\"RestockDate\"] = pd.to_datetime(inventory_df[\"RestockDate\"])\n",
    "        inventory_df = inventory_df[inventory_df[\"Quantity\"] < threshold]\n",
    "        inventory_df[\"DaysUntilRestock\"] = (inventory_df[\"RestockDate\"] - pd.Timestamp.today()).dt.days\n",
    "        monthly_summary = inventory_df.groupby(inventory_df[\"RestockDate\"].dt.to_period(\"M\")).size().reset_index()\n",
    "        monthly_summary.columns = [\"Month\", \"ItemsToRestock\"]\n",
    "        return inventory_df, monthly_summary\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"construct_inventory_report\": construct_inventory_report}\n",
    "\n",
    "pandas_176()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_13260\\174057361.py:11: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  forecast_df['ProjectedSales'] = forecast_df['ProjectedSales'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Develop a function `optimize_sales_forecast` that works on DataFrame `forecast_df` with columns 'Product', 'ProjectedSales', 'ForecastDate'. Convert 'ForecastDate' to DateTime format; Apply forward fill to handle missing 'ProjectedSales' values; Conduct a rolling window analysis to compute the 3-month moving average of sales; Return an extended DataFrame with moving averages along with original columns;\n",
    "@check_pandas_177\n",
    "def pandas_177():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def optimize_sales_forecast(forecast_df):\n",
    "        forecast_df['ForecastDate'] = pd.to_datetime(forecast_df['ForecastDate'])\n",
    "        \n",
    "        forecast_df['ProjectedSales'] = forecast_df['ProjectedSales'].fillna(method='ffill')\n",
    "        \n",
    "        forecast_df = forecast_df.sort_values(by='ForecastDate')\n",
    "        \n",
    "        forecast_df['3MonthMovingAvg'] = forecast_df['ProjectedSales'].rolling(window=3, min_periods=1).mean()\n",
    "        return forecast_df\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"optimize_sales_forecast\": optimize_sales_forecast}\n",
    "\n",
    "pandas_177()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `summarize_employee_performance` that processes DataFrame `performance_df` with 'EmployeeID', 'Score', 'ReviewDate'. Ensure 'ReviewDate' is converted into a datetime object; Replace missing 'Score' with the lowest non-zero score; Group by 'EmployeeID' to compute total and average score; Generate a DataFrame highlighting top performers with scores above a specified percentile score; Audit history, including evaluation of performance improvement over time;\n",
    "@check_pandas_178\n",
    "def pandas_178():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"summarize_employee_performance\": summarize_employee_performance}\n",
    "\n",
    "pandas_178()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `double_series_values` that takes a Series `input_series` and returns a Series with all values doubled.\n",
    "@check_pandas_179\n",
    "def pandas_179():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    def double_series_values(input_series):\n",
    "        return input_series * 2\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"double_series_values\": double_series_values}\n",
    "\n",
    "pandas_179()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `replace_zeros_with_mean` that takes a Series `data_series` and replaces all 0 values with the mean of the Series, returning the modified Series.\n",
    "@check_pandas_180\n",
    "def pandas_180():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def replace_zeros_with_mean(data_series):\n",
    "        mean_value = data_series[data_series != 0].mean()\n",
    "        data_series[data_series == 0] = mean_value\n",
    "        return data_series\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"replace_zeros_with_mean\": replace_zeros_with_mean}\n",
    "\n",
    "pandas_180()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Design a function `standardize_column_names` that accepts a DataFrame `df` and returns it with all column names set to lowercase.\n",
    "@check_pandas_181\n",
    "def pandas_181():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def standardize_column_names(df):\n",
    "        df.columns = df.columns.str.lower()\n",
    "        return df\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"standardize_column_names\": standardize_column_names}\n",
    "\n",
    "pandas_181()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `drop_duplicate_rows` that receives a DataFrame `df` and returns it with duplicate rows removed.\n",
    "@check_pandas_182\n",
    "def pandas_182():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def drop_duplicate_rows(df):\n",
    "        return df.drop_duplicates()\n",
    "    \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"drop_duplicate_rows\": drop_duplicate_rows}\n",
    "\n",
    "pandas_182()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `calculate_column_sums` that takes a DataFrame `df` and returns a Series containing the sum of each column.\n",
    "@check_pandas_183\n",
    "def pandas_183():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def calculate_column_sums(df):\n",
    "        return df.sum()\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"calculate_column_sums\": calculate_column_sums}\n",
    "\n",
    "pandas_183()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `extract_date_parts` that takes a Series `dates` of datetime objects and returns a DataFrame with columns 'Year', 'Month', and 'Day'.\n",
    "@check_pandas_184\n",
    "def pandas_184():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    def extract_date_parts(dates):\n",
    "        return pd.DataFrame({\n",
    "            'Year': dates.dt.year,\n",
    "            'Month': dates.dt.month,\n",
    "            'Day': dates.dt.day\n",
    "        })\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"extract_date_parts\": extract_date_parts}\n",
    "\n",
    "pandas_184()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define a function `concat_strings_in_column` that, given a DataFrame `df` and a column `text_col`, concatenates all strings in that column with a space in between, returning the result string.\n",
    "@check_pandas_185\n",
    "def pandas_185():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def concat_strings_in_column(df, text_col):\n",
    "        return ' '.join(df[text_col].astype(str))\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"concat_strings_in_column\": concat_strings_in_column}\n",
    "\n",
    "pandas_185()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `sort_by_index_descending` that accepts a DataFrame `df` and returns it sorted by its index in descending order.\n",
    "@check_pandas_186\n",
    "def pandas_186():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def sort_by_index_descending(df):\n",
    "        return df.sort_index(ascending=False)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"sort_by_index_descending\": sort_by_index_descending}\n",
    "\n",
    "pandas_186()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `filter_by_threshold` to take a DataFrame `df` and a column name `col`, returning a DataFrame including only rows where `col` is above a given threshold.\n",
    "@check_pandas_187\n",
    "def pandas_187():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    def filter_by_threshold(df, col, threshold):\n",
    "        return df[df[col] > threshold]\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"filter_by_threshold\": filter_by_threshold}\n",
    "\n",
    "pandas_187()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `get_unique_values` that takes a DataFrame `df` and a column `col`, returning a sorted array of unique values in the specified column.\n",
    "@check_pandas_188\n",
    "def pandas_188():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def get_unique_values(df, col):\n",
    "        return sorted(df[col].unique())\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"get_unique_values\": get_unique_values}\n",
    "\n",
    "pandas_188()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Develop a function `append_row_to_dataframe` that takes a DataFrame `df` and a dictionary `row_dict`, appending the dictionary as a new row, and returning the updated DataFrame.\n",
    "@check_pandas_189\n",
    "def pandas_189():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def append_row_to_dataframe(df, row_dict):\n",
    "        df = df.append(row_dict, ignore_index=True)\n",
    "        return df                   \n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"append_row_to_dataframe\": append_row_to_dataframe}\n",
    "\n",
    "pandas_189()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Construct a function `reset_index_and_name` that takes a DataFrame `df` and returns it with its index reset and the name of the index set to 'NewIndex'.\n",
    "@check_pandas_190\n",
    "def pandas_190():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    def reset_index_and_name(df):\n",
    "        df_reset = df.reset_index()\n",
    "        df_reset.index.name = 'NewIndex'\n",
    "        return df_reset\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"reset_index_and_name\": reset_index_and_name}\n",
    "\n",
    "pandas_190()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `swap_dataframe_columns` that accepts a DataFrame `df` and two column names `col1` and `col2`, swapping the values of these columns.\n",
    "@check_pandas_191\n",
    "def pandas_191():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    def swap_dataframe_columns(df, col1, col2):\n",
    "        df[col1], df[col2] = df[col2], df[col1]\n",
    "        return df\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"swap_dataframe_columns\": swap_dataframe_columns}\n",
    "\n",
    "pandas_191()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `rename_index_label` which receives a DataFrame `df`, renames its first index label to 'FirstRow', and returns the DataFrame.\n",
    "@check_pandas_192\n",
    "def pandas_192():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    def rename_index_label(df):\n",
    "        df.index.values[0] = 'FirstRow'\n",
    "        return df\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"rename_index_label\": rename_index_label}\n",
    "\n",
    "pandas_192()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Define a function `calculate_frequency_table` that, given a DataFrame `df` and a column `cat_col`, returns a DataFrame with a frequency count of each category with columns Category and count.\n",
    "@check_pandas_193\n",
    "def pandas_193():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    def calculate_frequency_table(df, cat_col):\n",
    "        return df[cat_col].value_counts().reset_index().rename(columns={'index': 'Category', cat_col: 'count'})\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"calculate_frequency_table\": calculate_frequency_table}\n",
    "\n",
    "pandas_193()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `remove_negative_entries` that takes a Series `numeric_series` and returns a Series with all negative entries removed.\n",
    "@check_pandas_194\n",
    "def pandas_194():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def remove_negative_entries(numeric_series):\n",
    "        return numeric_series[numeric_series >= 0]\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"remove_negative_entries\": remove_negative_entries}\n",
    "\n",
    "pandas_194()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `sort_column_values` that takes a DataFrame `df` and column name `col`, returning `df` sorted by `col` values in ascending order.\n",
    "@check_pandas_195\n",
    "def pandas_195():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "        # BELOW GOES YOUR CODE\n",
    "    def sort_column_values(df, col):\n",
    "        return df.sort_values(by=col, ascending=True)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"sort_column_values\": sort_column_values}\n",
    "\n",
    "pandas_195()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Design a function `drop_columns_by_name` that accepts a DataFrame `df` and a list of column names `drop_cols`, removing these columns and returning the modified DataFrame.\n",
    "@check_pandas_196\n",
    "def pandas_196():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def drop_columns_by_name(df, drop_cols):\n",
    "        return df.drop(columns=drop_cols)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"drop_columns_by_name\": drop_columns_by_name}\n",
    "\n",
    "pandas_196()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_13260\\520074131.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_13260\\520074131.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_13260\\520074131.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# Develop a function `strip_whitespace` that takes a DataFrame `df` and trims leading and trailing whitespace from all string entries.\n",
    "@check_pandas_197\n",
    "def pandas_197():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "        # BELOW GOES YOUR CODE\n",
    "    def strip_whitespace(df):\n",
    "        return df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"strip_whitespace\": strip_whitespace}\n",
    "\n",
    "pandas_197()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `duplicate_last_column` that receives a DataFrame `df` and duplicates its last column, appending the duplicate to the right of the DataFrame named as the original column with '_copy' appended.\n",
    "@check_pandas_198\n",
    "def pandas_198():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def duplicate_last_column(df):\n",
    "        last_column = df.columns[-1]\n",
    "        df[f\"{last_column}_copy\"] = df[last_column]\n",
    "        return df\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"duplicate_last_column\": duplicate_last_column}\n",
    "\n",
    "pandas_198()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `filter_top_n_rows_by_column` that takes a DataFrame `df`, a column `col`, and an integer `n`, returning the top n rows sorted by values in `col`.\n",
    "@check_pandas_199\n",
    "def pandas_199():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def filter_top_n_rows_by_column(df, col, n):\n",
    "        return df.nlargest(n, col)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"filter_top_n_rows_by_column\": filter_top_n_rows_by_column}\n",
    "\n",
    "pandas_199()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define a function `calculate_range_of_numeric_series` that takes a Series `numeric_series` and returns the range (max - min) of its values.\n",
    "@check_pandas_200\n",
    "def pandas_200():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def calculate_range_of_numeric_series(numeric_series):\n",
    "        return numeric_series.max() - numeric_series.min()\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"calculate_range_of_numeric_series\": calculate_range_of_numeric_series}\n",
    "\n",
    "pandas_200()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
